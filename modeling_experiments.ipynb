{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "import logging\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump,load\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupShuffleSplit,GroupKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport load_data\n",
    "%aimport evaluate\n",
    "import load_data\n",
    "import evaluate\n",
    "\n",
    "xml_file_loc=''\n",
    "imed_path=\"\"\n",
    "\n",
    "df = load_data.load_data(xml_file_loc, imed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"time_since_onset\"]=(df[\"ExaminationDate\"] - df[\"Date of onset\"]).apply(lambda x: x.days if not pd.isnull(x) else np.nan)\n",
    "df[\"Age\"]=df.apply(lambda x: x[\"ExaminationDate\"].year - x[\"PatientBirthDate\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit,GroupKFold\n",
    "\n",
    "random_state=2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create traing and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=[\"EDSS\"])\n",
    "\n",
    "X=df.drop(columns=[\"EDSS\",\"ExaminationDate\",'PatientID','PatientBirthDate','Date of onset','EthnicGroup'])\n",
    "groups=df[\"PatientID\"]\n",
    "Y=df[\"EDSS\"]\n",
    "\n",
    "outer_split=GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=random_state)\n",
    "cv=GroupKFold(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in outer_split.split(X,Y,groups=groups):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    groups_train, groups_test = groups.iloc[train_idx], groups.iloc[test_idx]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "numeric_transormer = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy='mean')),\n",
    "                                     (\"VarianceThreshold\",VarianceThreshold(0.0)),\n",
    "                                     (\"scaler\",StandardScaler())]).set_output(transform='pandas')\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "           (\"onehot\", OneHotEncoder(drop='first',sparse_output=False)),]).set_output(transform='pandas')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transormer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=preprocessor.fit(X_train)[\"num\"][\"VarianceThreshold\"].variances_\n",
    "preprocessor.fit(X_train)[\"num\"][\"VarianceThreshold\"].feature_names_in_[var<0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "feature_selector = Pipeline(steps=[(\"VarianceThreshold\",VarianceThreshold(0.1)),\n",
    "                                   \n",
    "                                   ]).set_output(transform='pandas')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Modeling:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oct_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
